---
title: "msb105_ass_1"
author: "Magnus Eidesmo"
date: last-modified
date-format: "dddd D MMM, YYYY"
csl: apa7.csl
lang: en-GB
format:
  html: default
  typst:
    papersize: a4
  pdf:
    documentclass: article
    number-sections: true
    keep-tex: true
    papersize: A4
    fig-pos: "H"
bibliography: 
- msb105_kilder.bib
- reproducibility1.bib
abstract: "A very short abstract. Put the abstract text here. One or two paragraphs summarising what follows below."
---

## Introduction
	
<!-- #What is this paper about?  -->
<!-- #What is discussed? -->
<!-- #Why is it of any consequence? -->

Vitenskapelig troverdighet bygger på dens evne til å levere pålitelige resultater som andre kan etterprøve. Som @mcnutt2014 uttrykker det: *"Science advances on a foundation of trusted discoveries. Reproducing an experiment is one important approach that scientists use to gain confidence in their conclusion."* Når forskning ikke lar seg gjenskape, undergraves denne tilliten. Den såkalte replikasjonskrisen har vist at store deler av forskning innen psykologi, medisin og samfunnsvitenskap ikke kan replikeres [@ioannidis2005b; @opensciencecollaboration2015]. Dette kan få avorlige følger - fra bortkastede forskningsressurser til redusert tillit til vitenskapelige anbefalinger, og ikke minst faren for at feilaktige resultater etableres som kunnskapsgrunnlag [@simmons2011].

Denne oppgaven diskuterer hvordan begrepene **reproduserbarhet** og **replikerbarhet** kan forstås, hvorfor de er avgjørende for vitenskapens pålitelighet, og hvilke tiltak som kan styrke forskningspraksissen. Det legges særlig vekt på spørsmålet om replikasjon bør være en norm, hvordan teknologiske verktøy som Quarto kan fremme reproduserbarhet, og hvilke utfordringer som fortsatt gjenstår




## Literature review

<!-- Smart stuff from others about the topic. -->
<!-- Use a least 20 citations, a least 5 of them must be new (not from the provided .bib file). -->
<!-- Use both in-line and normal citations. -->

## Discussion of the reseach question

<!-- -   Should replicability be the norm or is this to much to ask for now? -->
<!-- -   Can Quarto documents help with reproducibility? -->
<!-- -   What problems remains and how can these be solved? -->

## Conclusion


## References
<div id="refs"></div>

<!-- ## Notes -->

<!-- 1. Reproduserbarhet -->

<!-- “Science advances on a foundation of trusted discoveries. Reproducing an experiment is one important approach that scientists use to gain confidence in their conclusions. Recently, the scientific community was shaken by reports that a troubling proportion of peer-reviewed preclinical studies are not reproducible”.[@mcnutt2014] -->

<!-- 2. Replicability and Reproducibility -->

<!-- “Replication—The confirmation of results and conclusions from one study obtained independently in another—is considered the scientific gold standard.”(Jasny et al. 2011) -->

<!-- kan gjør ting på nytt med nye data, men fortsatt få det samme. -->

<!-- Reproducibility is a necessary, but not sufficient, condition for Replicability. -->

<!-- Peng mener at reproduserbarhet skal være nødvendig for å få lov til å publisere. -->
<!-- Should Reproducibility be a minimal requirement for publication? (Peng (2011) discusses this with regard to Computational Science) -->

<!-- 3. NSF: Robust and Reliable Science -->
<!-- (Bollen et al. 2015) -->
<!-- “robust and reliable” science refers to: research that is reproducible, replicable, and generalizable. -->

<!-- Reproducibility refers to: the ability of a researcher to duplicate the results of a prior study using the same materials and procedures used by the original investigator. -->

<!-- Replicability refers to: the ability of a researcher to duplicate the results of a prior study if the same procedures are followed but new data are collected. -->

<!-- Generalizability refers to: whether the results of a study apply in other contexts or populations that differ from the originals. -->

<!-- 5. What is research reproducibility? -->
<!--  (Goodman, Fanelli, and Ioannidis 2016) -->
<!-- - et forsøk på å definere enda grundigere, og mer opp imot bivitenskap -->

<!-- Methods reproducibility: “Methods reproducibility refers to the provision of enough detail about study procedures and data so the same procedures could, in theory or in actuality, be exactly repeated.” -->

<!-- Results reproducibility: “Results reproducibility (previously described as replicability) refers to obtaining the same results from the conduct of an independent study whose procedures are as closely matched to the original experiment as possible.” -->

<!-- Robustness and generalizability: “We briefly introduce these terms because they are sometimes used in lieu of the term reproducibility. Robustness refers to the stability of experimental conclusions to variations in either baseline assumptions or experimental procedures. It is somewhat related to the concept of generalizability (also known as transportability), which refers to the persistence of an effect in settings different from and outside of an experimental framework.” -->

<!-- 6. Publication bias -->

<!-- Om en studie skal bli publisert kan være avhengi av konklusjonen av studien. -->
<!-- - Det er få publiserte studier som har en negativ konklusjon. -->
<!-- - f.eks : Denne behandlingen har ingen effekt -->
<!-- I verste fall: forsknings artikkler er bare en stor samling av type 1 error -->
<!--   Type 1 error: forkaster H0 = når H0 = er sant -->
<!--   H0 er ofte den konsevative hypotesen, "ingen effekt" -->
<!-- Med en alpha = 0,05 vil vi forkaste H0 1 av 20ganger selv om H0 er sant. -->
<!--   «Det vil si, vi konkluderer med at det finnes en effekt når det i virkeligheten ikke gjør det (alt       sammen fordi vi var uheldige – eller kanskje heldige, dersom vi ønsker å bli publisert – og fikk et      uheldig utvalg). -->
<!--     Så selv om det finnes 100 lignende studier som ikke finner noen effekt, er det en risiko for at det      er den feilaktige du vil komme over i litteraturen. Dette kalles ofte ‘skuffeproblemet’ (File Drawer     Problem), etter Rosenthal (1979). -->

<!-- (Simmons, Nelson og Simonsohn, 2011) -->
<!-- Kanskje den mest kostbare feilen er et falskt positivt funn, altså en feilaktig forkastelse av en nullhypotese. -->

<!-- For det første, når de først dukker opp i litteraturen, er falske positive spesielt seiglivede. -->
<!-- Fordi nullresultater kan ha mange mulige årsaker, er mislykkede forsøk på å replikere tidligere funn aldri avgjørende. -->

<!-- I tillegg, fordi det er uvanlig at prestisjetunge tidsskrifter publiserer nullfunn eller eksakte replikasjoner, har forskere liten motivasjon til å engang forsøke det. -->

<!-- For det andre sløser falske positive med ressurser: De inspirerer til investering i resultatløse forskningsprogrammer og kan føre til ineffektive politiske endringer. -->

<!-- Til slutt risikerer et fagfelt som er kjent for å publisere falske positive å miste sin troverdighet.» (Simmons, Nelson og Simonsohn, 2011) -->

<!-- 9. Publication bias and meta-analysis -->

<!-- Tar for seg mange artikkler innen et område og prøver å finne en sammenfatning om det generelle svaret. -->
<!--   publication bias vil også ha betydning for meta-analyse -->

<!-- “More alarming is the general paucity in the literature of negative data. In some fields, almost all published studies show formally significant results so that statistical significance no longer appears discriminating” (Young, Ioannidis, and Al-Ubaydli 2008) -->

<!-- 10. The Replication Crisis -->

<!-- Startet i psykologi, men har spredt seg raskt til de andre feltene innefor forskning. -->

<!-- Simmons, Nelson, and Simonsohn (2011) “proves” that you will get, or at least feel, younger by listening to “When I’m Sixty-Four” by The Beatles. -->

<!-- Simmons, Nelson, and Simonsohn (2011) -->
<!--   Etter at de "beviste" artiklen om at man blir yngere ved å høre på "when im sixty-four" av The Beatles,   kom de med en løsning for å ungå at slike forskningsartikkler ikke skulle komme gjennom. -->
<!--     De kom med en list for både forfattere (6) og redaktørene(4). -->

<!-- Why Most Published Research Findings Are False Ioannidis (2005) -->
<!--   “There is increasing concern that in modern research, false findings may be the majority or even the     vast majority of published research claims [6–8]. However, this should not be surprising. It can be      proven that most claimed research findings are false.” -->

<!-- Again, and again, and again Jasny et al. (2011) -->

<!-- 12. Big replication studies in psychology -->

<!-- Estimating the reproducibility of psychological science Brian A. Nosek and et al (2015) -->
<!--   - 270 forskre ble etterforsket -->
<!--   - Forsøkte å replikere 100 studier fra de siste 3 årene hentet fra 3 av de mest anerkjente                 tidsskriftene   i feltet. -->
<!--   - Resultater: Replikasjonseffektene var halvparten så store som de opprinnelige effektene. -->
<!--   - Resultater: Nittisju prosent av de opprinnelige studiene hadde signifikante resultater (p < .05).        Trettiseks prosent av repliksjonene hadde signifikante resultater. -->
<!--   - Resultater: Oppsummert, en stor andel av replikasjonene gjenskapte ikke bevis som støttet de             opprinnelige funnene, til tross for bruk av høyeffektive design og originalt materiale når det var       tilgjengelig. -->

<!-- Many labs 2: Investigating variation in replicability across samples and settings Klein et al. (2018). See Collaboration (2015) for abstract. -->

<!-- “We conducted preregistered replications of 28 classic and contemporary published findings, with protocols that were peer reviewed in advance, to examine variation in effect magnitudes across samples and settings.” -->

<!-- “Using the conventional criterion of statistical significance (p < .05), we found that 15 (54%) of the replications provided evidence of a statistically significant effect in the same direction as the original finding.” -->


<!-- 15. What about economics? -->

<!-- Good intentions! (Frisch 1933) -->

<!-- 1960, big economic models -->
<!--   Difficult to move from one mainframe to another -->
<!--   Only results published, replication/reproduction nearly impossible -->

<!-- 16. The JMCB project (1982) -->
<!-- 1982 The Journal of Money, Credit and Banking Project (NSF sponsored) -->
<!-- - Replikasjon (med innsendte datasett), altså i moderne forstand mer et forsøk på å teste                  reproduserbarhet. -->
<!-- - Resultater: Lyktes med full replikasjon for 2 av over 70. -->
<!-- - Resultater: Noen flere ga nesten de opprinnelige resultatene. -->
<!-- - Resultater: Mange var umulige å replikere på grunn av manglende data, feil i dataprogrammer, manglende   dokumentasjon osv. -->
<!-- - Mange forfattere ignorerte rett og slett forespørselen om data og kode. -->

<!-- “It would be embarrassing to reveal the findings of the Project save for our belief that the findings would be little different from any other major economics journal” -->

<!-- 18. “The Solution” -->
<!-- Code and data archives at the journals -->

<!-- American Economic Association data archive, (“American Economic Association,” n.d. ) -->

<!-- Virket denne løsningen? -->
<!-- Do economics journal archives promote replicable research? (McCullough, McGeary, and Harrison 2008) -->

<!-- "Abstract. All the long-standing archives at economics journals do not facilitate the re-production of published results. The data-only archives at Journal of Business and Economic Statistics and Economic Journal fail in part because most authors do not contribute data. Results published in the FRB St. Louis Review can rarely be reproduced using the data+code in the journal archive." -->

<!-- 19. “Extension of the solution” -->
<!-- Research Objects, (Bechhofer et al. 2013) -->
<!-- “Research Objects, semantically rich aggregations of resources that provide the “units of knowledge” which supply structure for delivery of information as Linked Data.” -->

<!-- DataCite - A global registration agency for research data, Brase (2009) -->
<!--   International co-operations to register data sets and give them a unique DOI (Document Object            Indentifier) -->

<!-- EU initiative Access to and Preservation of Scientific Information in Europe: Report on the Implementation of Commission Recommendation C(2012) 4890 Final. (2015) -->
<!-- “This report provides an overview on access to and preservation of scientific information in the EU Member States as well as Norway and Turkey.” -->

<!-- 20. Another solution, “computable documents” -->

<!-- What if the code is an integral part of the article? -->
<!-- What is to be sent to the Journal is: -->
<!-- - one document containing the text and -->
<!-- - the code to read in the data and -->
<!-- - the code to calculate the different models and -->
<!-- - the code to test them and -->
<!-- - the code to report the results. -->
<!-- What would be submitted would be, together with the data, a fully reproducible document -->

<!-- 21. Another solution, “computable documents” -->

<!-- The main idea is often attributed to Donald E. Knuth (1992), although Knuth explicitly points out that it was not his idea (D. E. Knuth 1984) -->
<!--   Knuths main goal seems to be to improve the quality of the program documentation (and indirectly the     quality of the code) with WEB. -->

<!-- 22. Another solution, “computable documents”  -->
<!-- “In the mid 1980’s, researchers at our laboratory noticed that a few months after completing a project, the researchers were usually unable to reproduce their own computational work without considerable agony. In 1991, the concept of electronic documents solved this problem by making scientific computations reproducible.”(Schwab, Karrenbach, and Claerbout 1995) -->
<!--   unix makefiles -->

<!-- Connection between code and reproducibility. All code necessary to generate figures freely avaiable (WaveLab a Matlab (Matlab is proprietary software) library).(Buckheit and Donoho 1995) -->

<!-- 23. Another solution, “computable documents” -->
<!-- “It is important, if not essential, to integrate the computations and code used in data analyses, methodological descriptions, simulations, and so on with the documents that describe and rely on them.” (Gentleman and Lang 2007) -->

<!-- “We introduce the concept of a compendium as both a container for the different elements that make up the document and its computations (i.e. text, code, data, …), and as a means for distributing, managing and updating the collection.” -->

<!-- “The step from disseminating analyses via a compendium to reproducible research is a small one. By reproducible research, we mean research papers with accom- panying software tools that allow the reader to directly reproduce the results and employ the methods that are presented in the research paper.” -->

<!-- “a compendium has one, or more, self-contained live documents that can be regenerated in absolute detail by others, and that can often be used in contexts other than the author’s original work.” -->

<!-- “We define a dynamic document as an ordered composition of code chunks and text chunks that describe and discuss a problem and its solution. The ordering of the chunks need not be simply sequential but can support rich and complex document structures.” -->

<!-- “The mechanism or system used to transform a dynamic document into some desired output or view will be called a transformer.” -->

<!-- In Gentleman (2005) parts of Golub et al. (1999) is reproduced as a computable compendium. -->

<!-- 25. Implementations I -->
<!-- Sweave, executable code (R or Splus) in LaTex documents, (Leisch 2002) -->
<!--   Er forgjengeren til knitr -->
<!-- Knitr, (Xie 2014), (Xie 2015) and (Xie 2020) -->
<!--   R code in LaTex documents (like Sweave), but also support for R Markdown (Allaire et al. 2020),          (Tierney, n.d.), (Xie, Allaire, and Grolemund 2018) and (Riederer, n.d.) -->
<!--   Markdown Gruber and Swartz (n.d.), plain text with simple markup. Intended for Grubers web site. -->
<!--   R Markdown, markdown with R code-chuncks -->
<!-- RStudio (RStudio Team 2020), IDE for R supporting R Markdown and knitr -->

<!-- 26. Implementations II -->
<!-- R Notebook, document type supported by RStudio that implements a notebook interface, i.e. output is returned to the notebook when it is run -->
<!--   Code should be run sequentially, but each code-chunck can be run individually. -->
<!--   Support LaTex code for mathematical typesetting. -->
<!--   pandoc, (“Pandoc - Pandoc User’s Guide,” n.d. ), functions as the transformer (from Gentleman and Lang     (2007)) and can transform a R Markdown document into many different formats, including MS Word, html     and pdf (via LaTex). -->

<!-- Introductory books on R, (Lander 2017) and Data Science, (Grolemund and Wickham, n.d.) often includes chapters on how to write dynamic computable documents in R Studio -->

<!-- 27. Implementations III -->
<!-- Quarto documents -->
<!--   The updated and more robust version of R Notebook/.Rmd documents -->
<!--   Still uses pandoc, output to html, pdf, docx and other formats -->
<!--   Supports LaTeX for mathematics -->
<!--   Support Zotero/BiBTeX for citations and references -->
<!--   R-code in code-chuncks -->






