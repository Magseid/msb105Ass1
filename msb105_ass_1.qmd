---
title: "msb105_ass_1"
author: "Magnus Eidesmo"
date: last-modified
date-format: "dddd D MMM, YYYY"
csl: apa7.csl
lang: nb-NO
format:
  html: default
  typst:
    papersize: a4
  pdf:
    documentclass: article
    number-sections: true
    keep-tex: true
    papersize: A4
    fig-pos: "H"
bibliography: 
- msb105_kilder.bib
- reproducibility.bib
abstract: "A very short abstract. Put the abstract text here. One or two paragraphs summarising what follows below."
---
## Introduction
Vitenskapelig troverdighet bygger på dens evne til å levere pålitelige resultater som andre kan etterprøve. Som @mcnutt2014 uttrykker det: *"Science advances on a foundation of trusted discoveries. Reproducing an experiment is one important approach that scientists use to gain confidence in their conclusion."* Når forskning ikke lar seg gjenskape, undergraves denne tilliten. Den såkalte replikasjonskrisen har vist at store deler av forskning innen psykologi, medisin og samfunnsvitenskap ikke kan replikeres [@ioannidis2005b; @opensciencecollaboration2015]. Dette kan få alvorlige følger - fra bortkastede forskningressurser til redusert tillit til vitenskapelige anbefalinger, og ikke minst faren for at feilaktige resultater etableres som kunnskapsgrunnlag [@simmons2011].

Denne oppgaven diskuterer hvordan begrepene reproduserbarhet og replikerbarhet kan forstås, hvorfor de er avgjørende for vitenskapens pålitelighet, og hvilke tiltak som kan styrke forskningspraksissen. Det legges særlig vekt på spørsmålet om replikasjon bør være en norm, hvordan teknologiske verktøy som Quarto kan fremme reproduserbarhet, og hvilke utfordringer som fortsatt gjenstår

## Literature review
### Reproduserbarhet og Replikerbarhet
Et sentralt skille i forskningdiskusjonene er mellom **reproduserbarhet** og **replikerbarhet**. @bollen2015 definerer reproduserbarhet som muligheten for å gjenskape resultater med de samme data og metoden, mens replikerbarhet innebærer å teste en studie ved å bruke nye data, men med samme metode. @committeeonreproducibilityandreplicabilityinscience2019a tydeliggjør dette skillet ytterliger, og argumenterer for at begge dimensjoner må være til stede for at forskning skal være pålitelig. @goodman2016b skiller i tillegg mellom *"methods reproducibility, results reproducibility* og *robustness/generalizability",* noe som viser at begrepet favner flere nivåer.

@peng2011 fremhever at reproduserbarhet burde være et minimumskrav for å kunne publisere i beregningsorienterte fag, på grunn av at full replikasjon ofte er urealistisk. @jasny2011b går enda lengre og omtaler replikerbarhet som vitenskapens "gullstandard". Dette støttes videre av @maxwell2015a , som viser hvordan manglende replikasjon undergraver fagfeltets kumulative kunnskapsutvikling.

### Publikasjonsbias og falske positive
Et av de mest gjennomgående problemene for vitenskapens pålitelighet er publikasjonsbias, altså tendensen til at studier med signifikante resultater får prioritet i publiseringsprosessen. Allerede på 70-tallet beskrev @rosenthal1979 dette som *"file drawer problem"*, hvor nullresultater forblir liggende upublisert i forskerens skuff. Konsekvensene av dette er at den vitenskapelige litteraturen gir en overdrevent positivt bilde av forskningsfeltet.

Denne skjevheten forsterkes av hvordan analyser faktisk gjennomføres. @simmons2011 viste hvordan forskere gjennom små justeringer i analysevalg - såkalt "p-hacking" - kan produsere tilsynelatende robuste funn som i virkeligheten er falske positive. Når slike resultater først blir publisert, blir de sjeldent korrigert, fordi nullresultater ofte ikke finner veien inn i disse prestisjetidsskriftene.

Meta-analyser, som har som mål å gi et samlet bilde av forskningstatus, rammes derfor også av dette. som @young2008 påpeker, bygger de på den publiserte litteraturen, og blir derfor indirekte farget av publikasjonsbias. Nyere analyser viser at problemet har tiltalt: @fanelli2012a dokumenterer en tydelig nedgang i andelen nullfunn på tvers av fagfelt og land, noe som bekrefter en systematisk skjevhet mot positive resultater.

Denne dynamikken har strukturelle årsaker. @smaldino2016a argumenterer for at dagens incentivsystemer i realiteten fremmer "dårlig vitenskap": Forskere blir i større grad belønnet for kvantiteten av signifikante funn enn for metodisk grundighet eller vilje til å replikere tidligere resultater. Dermed blir publikasjonsbias ikke bare en konsekvens av individuelle valg, men et mønster som formes av selve forsknings-systemets belønningmekanismer.

### Dokumenterte funn om replikasjon
@ioannidis2005b argumenterte tidlig for at majoriteten av publiserte forskningsfunn sannsynligvis er falske, basert på metodiske svakheter, lav statistisk styrke og bias. Denne bekymringen ble senere empirisk dokumentert gjennom @opensciencecollaboration2015b, som forsøkte å replikere 100 psykologiske studier. Av disse studiene var det kun 36% som ga signifikante resultater, og effektstørrelsen var betydelig redusert. @nosek2015 understøtter disse funnene og peker på at mangel på transparens og deling av data er sentrale årsaker.

@klein2018b gjennomførte "Many Labs 2" prosjektet, hvor 28 klassiske og nyere psykologiske funn ble forsøkt replikert på tvers av ulike utvalg og settinger. Resultatene viste at bare litt over halvparten av forsøkene resulterte i signifikante effekter i samme retning som den originale studien. Dette viser at selv når funn kan bekreftes, fremstår de ofte som svakere enn først rapportert.

@camerer2018 fant lignene mønstre i sin evaluering av 21 samfunnsvitenskapelige eksperimenter publisert i *Nature* og *Science* mellom 2010 og 2015. Omtrent 62% av studiene kunne replikeres, men effektene var i snitt om lag 50% mindre enn i de opprinnelige artiklene. Disse resultatene er særlig oppsiktsvekkende ettersom at de gjelder studier fra de mest prestisjetunge tidsskriftene. Når selv forsknings som setter standarden for kvalitet og innflytelse viser begrenset replikerbarhet, understrekes alvoret i utfordringen for vitenskapelig pålitelighet.

Innen økonomi viste JMCB-prosjektet på 1980-tallet at bare 2 av 70 analyser kunne reproduseres fullt ut [@dewald1986b]. @mccullough2008a viste senere at selv tidsskrifter med dataarkiv ikke nødvendigvis ikke oppnår reproduserbarhet, fordi forfattere ofte leverer mangelfull kode og dokumentasjon. Dette peker på at tekniske løsninger som dataarkiv ikke er tilstrekkelige alene.

### Løsninger: Åpen vitenskap og tekniske rammeverk
For å møte disse utfordringene med lav reproduserbarhet og replikerbarhet er det foreslått en rekke tiltak. Open science-initiativer, som preregistreing og obligatorisk deling av data og kode, er blant de mest utbredte [@nosek2015]. @dudda viser i en bred kartlegging at ulike intervensjoner er tatt i bruk, men at kunnskapsgrunnlaget for hvor effektive de faktisk er, fortsatt er begrenset. @chakravorti2025 peker samtidig på at oppfatningen av hva reproduserbarhet innebærer varierer betydelig mellom land og fagfelt, og at både incentiver og ressurstilgang gjør enhetlige standarder vanskelig å etablere.

På den tekniske siden har et konseptet *computable documents* hatt stor innflytelse. Allerede på 1980-tallet introduserte @knuth1984b ideen om *literate programming*, hvor kode og forklarende tekst integreres for å gjøre programmer mer forståelige og vedlikeholdbare. Denne tankegangen ble videreført av @gentleman2007b, som lanserte ideen om *compendia* og *dynamic documents* - rammeverk som gjør det mulig å samle kode, data og beskrivelser i en helhetlig enhet for å sikre transparens.

Slike ideer ble etterhvert gjort praktiske gjennom verktøy som Sweave [@leisch2002], knitr [@xie2014b] og R Markdown [@allaire2020b], som åpnet for at analyser og tekst kunne integreres i ett dynamisk dokument. Quarto [@allaire2024a] representerer den nyeste videreutviklingen, med støtte for flere programmeringsspråk og formater, samt innebygget håndtering av referanser. I følge @ziemann2023 bygger beregningsreproduserbarhet på fem sentrale "søyler": åpen datadeling, kodedeling, dokumentasjon, standardisering og bruk av åpne plattformer. Dette er prinsipper som verktøy som Quarto i stor grad kan understøtte.

## Diskusjon av forskningsspørsmål
Replikerbarhet løftes ofte fram som vitenskapens gullstandard [@jasny2011b]. Likevel er det urealistisk å gjøre replikerbarhet til normen i alle fagfelt, gitt kostnadene og mangel på incentiver. Flere har derfor foreslått å se på reproduserbarhet som et minimumskrav for publisering, mens replikerbarhet forbeholdes studier med særlig stor betydning [@maxwell2015a; @peng2011].

Quarto kan spille kan spille en viktig rolle i å styrke reproduserbarhet ved å kombinere tekst, kode, data og referanser i ett dokument. Dette gir en mer transparent arbeidsflyt og gjør analyser lettere å etterprøve.

Samtidig gjenstår flere utfordringer. Incentivsystemet i akademia belønner først og fremst nye og signifikante funn, noe som svekker motivasjonen for replikasjonsstudier [@simmons2011; @smaldino2016a]. I tillegg viser @chakravorti2025 at forståelsen av reproduserbarhet varier mellom kontekster, noe som gjør at standardisering kan være krevende.

## Konklusjon
Reproduserbarhet og replikerbarhet er avgjørende for vitenskapens troverdighet. Et realistisk mål er å gjøre reproduserbarhet til publikasjonskrav, mens replikasjon oppmuntres i utvalgte tilfeller.

Tekniske rammeverk som Quarto kan bidra til mer transparente og etterprøvbare arbeidsprosesser, men de må kombineres med incentiver og opplæring for å få en reel effekt. Initiativer innen åpen vitenskap og nye verktøy peker i riktig retning [@dudda; @nosek2015], men det gjenstår et betydelig arbeid for å etablere en forkningskultur som er både robust og pålitelig.

## References
<div id="refs"></div>







